{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# HW1 - Q3: Face Recognition with Eigenfaces (40 points)\n","\n","**Keywords**: Principal Component Analysis (PCA), Eigenvalues and Eigenvectors\n","\n","**About the dataset**: \\\n","[*Labeled Faces in the Wild*](http://vis-www.cs.umass.edu/lfw/) dataset consists of face photographs designed for studying the problem of unconstrained face recognition. The original dataset contains more than 13,000 images of faces collected from the web.\n","\n","**Agenda**:\n","* In this programming challenge, you will be performing face recognition on the *Labeled Faces in the Wild* dataset using PyTorch. \n","* First, you will do Principal Component Analysis (PCA) on the image dataset. PCA is used for dimentionality reduction which is a type of unsupervised learning.\n","* You will be applying PCA on the dataset to extract the principal components (Top $k$ *eigenvalues*). \n","* As you will see eventually, the reconstruction of faces from these *eigenvalues* will give us the *eigen-faces* which are the most representative features of most of the images in the dataset. \n","* Finally, you will train a simple PyTorch Neural Network model on the modified image dataset.\n","* This trained model will be used prediction and evaluation on a test set.\n","\n","**Note:**\n","* Run all the cells in order.\n","* **Do not edit** the cells marked with !!DO NOT EDIT!!\n","* Only **add your code** to cells marked with !!!! YOUR CODE HERE !!!!\n","* Do not change variable names, and use the names which are suggested."],"metadata":{"id":"lJCEyyf3IlRw"}},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"b2ivsajX4yuy"}},{"cell_type":"code","source":["# !!DO NOT EDIT!!\n","# loading the dataset directly from the scikit-learn library (can take about 3-5 mins)\n","import numpy as np\n","from sklearn.datasets import fetch_lfw_people\n","dataset = fetch_lfw_people(min_faces_per_person=80)\n","\n","# each 2D image is of size 62 x 47 pixels, represented by a 2D array. \n","# the value of each pixel is a real value from 0 to 255.\n","count, height, width = dataset.images.shape\n","print('The dataset type is:',type(dataset.images))\n","print('The number of images in the dataset:',count)\n","print('The height of each image:',height)\n","print('The width of each image:',width)\n","\n","# sklearn also gives us a flattened version of the images which is a vector of size 62 x 47 = 2914.\n","# we can directly use that for our exercise\n","print('The shape of data is:',dataset.data.shape)"],"metadata":{"id":"OARGSLGW50J8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["For optimum performance, we have only considered people who have more than 80 images. This restriction notably reduces the size of the dataset.\\\n","Now let us look at the labels of the people present in the dataset"],"metadata":{"id":"F_f1TP1D53Ss"}},{"cell_type":"code","source":["# !!DO NOT EDIT!!\n","# create target label - target name pairs\n","targets = [(x,y) for x,y in zip(range(len(np.unique(dataset.target))), dataset.target_names)]\n","print('The target labels and names are:\\n', targets)"],"metadata":{"id":"7Rvb3xDT51Ky"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"3A_oqICv4tYn"}},{"cell_type":"markdown","source":["### **(a) Preprocessing:** Using the `train_test_split` API from sklearn, split the data into train and test dataset in the ratio 3:1. Use `random_state=42`. \n","### For better performance, it is recommended to normalize the features which can have different ranges with huge values. As all our features here are in the range [0,255],  it is not explicitly needed here. However, it is a good exercise. Use the `StandardScaler` class from sklearn and use that to normalize X_train and X_test. Validate and show your  result by printing the first 5 columns of 5 images of X_train (This result can vary from pc to pc). (5 points)"],"metadata":{"id":"nEj1Gbc2JDn8"}},{"cell_type":"code","source":["# !!DO NOT EDIT!!\n","X = dataset.data \n","y = dataset.target"],"metadata":{"id":"2Olrh2zv6Hv1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#######\n","# !!!! YOUR CODE HERE !!!!\n","\n","# output variable names -  X_train, X_test, y_train, y_test\n","#######"],"metadata":{"id":"6TyhO_2k3zhd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"HU0xRjui426w"}},{"cell_type":"markdown","source":["### **(b) Dimentionality reduction** : In this section, use the `PCA` API from sklearn to extract the top 100 principal components of the image matrix and fit it on the training dataset. We can then visualize some of the top few components as an image (eigenfaces). (5 points)"],"metadata":{"id":"kKI0kyPGJdgh"}},{"cell_type":"code","source":["#######\n","# !!!! YOUR CODE HERE !!!!\n","# initialize PCA API from sklearn with n_components. Also set svd_solver=\"randomized\" and whiten=True in the initialization parameters.\n","\n","# output variable name -  pca\n","#######"],"metadata":{"id":"C9tE3opr4GOF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Now we will plot the most representative eigenfaces: "],"metadata":{"id":"R8OkkCsk68pB"}},{"cell_type":"code","source":["# !!DO NOT EDIT!!\n","# Helper function to plot\n","import matplotlib.pyplot as plt\n","def plot_gallery(images, titles, height, width, n_row=2, n_col=4):\n","    plt.figure(figsize=(2* n_col, 3 * n_row))\n","    plt.subplots_adjust(bottom=0, left=0.01, right=0.99, top=0.90, hspace=0.35)\n","    for i in range(n_row * n_col):\n","        plt.subplot(n_row, n_col, i + 1)\n","        plt.imshow(images[i].reshape((height, width)), cmap=plt.cm.gray)\n","        plt.title(titles[i], size=12)\n","        plt.xticks(())\n","        plt.yticks(())"],"metadata":{"id":"2kScf2z86_4j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# !!DO NOT EDIT!!\n","# get the 100 eigen faces and reshape them to original image size which is 62 x 47 pixels \n","eigenfaces = pca.components_.reshape((n_components, height, width))\n","\n","# plot the top 8 eigenfaces\n","eigenface_titles = [\"eigenface %d\" % i for i in range(eigenfaces.shape[0])]\n","plot_gallery(eigenfaces, eigenface_titles, height, width)\n","\n","plt.show()"],"metadata":{"id":"w6v88C5-7BjE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"TkATsaLd44Sz"}},{"cell_type":"markdown","source":["### **(c) Face reconstruction:** In this section, we will reconstruct an image from its point projected on the principal component basis. Project the first three faces on the eigenvector basis using PCA models trained with varying number of principal components. Using the projected points, reconstruct the faces, and visualize  the images. Your final output should be a $3\\times 5$ image matrix, where the rows are the data points, and the columns correspond to original image and reconstructed image for n_components$=[10,100,150,500]$. (15 points)"],"metadata":{"id":"j1FdQiK6Qdzi"}},{"cell_type":"code","source":["#######\n","# !!!! YOUR CODE HERE !!!!\n","\n","#######"],"metadata":{"id":"l04GqaLPNHta"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"c3r-D9dG7FcD"}},{"cell_type":"markdown","source":["### **(d) Prediction:** In this section, we will train a neural network classifier in **PyTorch** on the transformed dataset. This classifier will help us with the face recognition task. Complete each of the steps below.\n","### For PyTorch reference see [documentation](https://pytorch.org/docs/stable/index.html). (15 points)"],"metadata":{"id":"Lj8zlLl6Jl7D"}},{"cell_type":"code","source":["# !!DO NOT EDIT!!\n","# define imports here\n","import torch\n","import torch.nn as nn"],"metadata":{"id":"G8ca5E8SOttb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Before we start training, we need to transform the training and test dataset to reduced forms (100 dimensions) using the pca function defined in (b).\n","### we will also need to move the train and test dataset to torch tensors in order to work with pytorch."],"metadata":{"id":"sZJW0AG8FDfc"}},{"cell_type":"code","source":["#######\n","# !!!! YOUR CODE HERE !!!!\n","# 1. project X_train and X_test on orthonormal basis using the PCA API initialized in part (b). \n","\n","\n","# 2. now convert X_train_pca, X_test_pca, y_train and y_test to torch.tensor. For y_train and y_test, set dtype=torch.long\n","\n","\n","# output variable names -  X_train_pca_torch, X_test_pca_torch, y_train_torch, y_test_torch\n","#######"],"metadata":{"id":"AX9tNmMAOvHD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#######\n","# !!!! YOUR CODE HERE !!!!\n","# 3. We will implement a simple multilayer perceptron (MLP) in pytorch with one hidden layer. \n","# Using this neural network model, we will train on the transformed dataset.\n","class MLP(torch.nn.Module):\n","  def __init__(self):\n","    super(MLP, self).__init__()\n","    # Initalize various layers of MLP as instructed below\n","    # DO: initialze two linear layers: 100 -> 1024  and 1024-> 5\n","\n","    # DO: initialize relu activation function\n","\n","    # DO: initialize LogSoftmax\n","\n","  def forward(self, x):\n","    # DO: define the feedforward algorithm of the model and return the final output\n","\n","#######"],"metadata":{"id":"CyX7c0WTOyIP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#######\n","# !!!! YOUR CODE HERE !!!!\n","# 4. create an instance of the MLP class here\n","\n","# 5. define loss (use negative log likelihood loss: torch.nn.NLLLoss)\n","\n","# 6. define optimizer (use torch.optim.SGD (Stochastic Gradient Descent)). \n","# Set learning rate to 1e-1 and also set model parameters\n","\n","#######\n","\n","# !!DO NOT EDIT!!\n","# 7. train the classifier on the PCA-transformed training data for 500 epochs\n","# This part is already implemented.\n","# Go through each step carefully and understand what it does.\n","for epoch in range(501):\n","  # reset gradients\n","  optimizer.zero_grad()\n","\n","  # predict\n","  output=model(X_train_pca_torch)\n","\n","  # calculate loss\n","  loss=criterion(output, y_train_torch)\n","\n","  # backpropagate loss\n","  loss.backward()\n","\n","  # performs a single gradient update step\n","  optimizer.step()\n","\n","  if epoch%50==0:\n","    print('Epoch: {}, Loss: {:.3f}'.format(epoch, loss.item()))"],"metadata":{"id":"qO6JT3gx4O7X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# !!DO NOT EDIT!!\n","# predict on test data\n","predictions = model(X_test_pca_torch) # gives softmax logits\n","y_pred = torch.argmax(predictions, dim=1).numpy() # get the labels from prdictions: nx5 -> nx1"],"metadata":{"id":"oKk6czdpTZu3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# !!DO NOT EDIT!!\n","# here, we will print the multi-label classification report: precision, recall, f1-score etc.\n","from sklearn.metrics import classification_report\n","target_names=[y for x,y in targets]\n","print(classification_report(y_test, y_pred, target_names=target_names))\n","\n","# let us validate some of the predictions by plotting images\n","# display some of the results\n","def title(y_pred, y_test, target_names, i):\n","    pred_name = target_names[y_pred[i]].rsplit(\" \", 1)[-1]\n","    true_name = target_names[y_test[i]].rsplit(\" \", 1)[-1]\n","    return \"predicted: %s\\ntrue:      %s\" % (pred_name, true_name)\n","\n","prediction_titles = [\n","    title(y_pred, y_test, target_names, i) for i in range(y_pred.shape[0])\n","]\n","\n","plot_gallery(X_test, prediction_titles, height, width)"],"metadata":{"id":"BfagbqzTfj24"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"6t3joN2Y46Uu"}}]}